# Set to true to log full AI messages sent and received. Dest: ~/.config/tmuxai/debug/
debug: false

# Maximum context size in tokens, reaching 80% triggers squashing
max_context_size: 100000

# Maximum number of lines to capture during each message
max_capture_lines: 200

# Wait interval when exec pane is considered busy (used in observe and watch modes)
wait_interval: 5

default_model: "gemini-flash" # If empty uses the first one

models:
  fast:
    provider: "openrouter"
    model: "anthropic/claude-haiku-4.5"
    api_key: "sk-or-your-openrouter-key"

  smart:
    provider: "openrouter"
    model: "google/gemini-2.5-prod"
    api_key: "sk-or-your-openrouter-key"

  # You can use any chat completion compatible endpoint as base_url
  anthropic:
    provider: "openrouter"
    model: "claude-3-5-sonnet-20241022"
    api_key: "your-anthropic-api-key"
    base_url: "https://api.anthropic.com"

  local-llama:
    provider: "openrouter"
    model: "gemma3:1b"
    api_key: "sk-or-your-openrouter-key"
    base_url: http://localhost:11434/v1

  # Responses API
  codex:
    provider: "openai"
    model: "gpt-5-codex"
    api_key: "sk-or-your-openrouter-key"

  azure-gpt4:
    provider: "azure"
    model: "gpt-4o"
    api_key: "your-azure-openai-api-key"
    api_base: "https://your-resource.openai.azure.com/"
    api_version: "2025-04-01-preview"
    deployment_name: "gpt-4o"

# Confirm before AI executes a command
exec_confirm: true

# Confirm before AI sends a key
send_keys_confirm: true

# Confirm before AI pastes a multiline text
paste_multiline_confirm: true

whitelist_patterns:
  - '^find(\s+.*)?$'
  - '^pwd\s*$'
  - '^cat(\s+.*)?$'

blacklist_patterns:
  - 'rm\s+'
  - 'mv\s+'
  - 'dd\s+'

# Prompts customization, see prompts.go for more details
prompts:
  base_system: |
    xxx

  chat_assistant: |
     xxx

  chat_assistant_prepared: |
     xxx

  watch: |
     xxx
